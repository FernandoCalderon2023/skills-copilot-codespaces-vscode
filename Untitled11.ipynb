{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandoCalderon2023/skills-copilot-codespaces-vscode/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbce46b9-c5cb-4d4f-a195-050809b76036",
      "metadata": {
        "id": "dbce46b9-c5cb-4d4f-a195-050809b76036"
      },
      "source": [
        "## Comprehensive Guide for Training YOLOv7 Using Docker on a Server\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By Fernando Miguel Calderon Villanueva"
      ],
      "metadata": {
        "id": "P3sD-MXJS-O2"
      },
      "id": "P3sD-MXJS-O2"
    },
    {
      "cell_type": "markdown",
      "id": "f75fa5a3-768b-478f-b5de-a32ff178f6ea",
      "metadata": {
        "id": "f75fa5a3-768b-478f-b5de-a32ff178f6ea"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7698edd-7737-459d-8eef-f45f20b6e274",
      "metadata": {
        "id": "a7698edd-7737-459d-8eef-f45f20b6e274"
      },
      "source": [
        "\n",
        "This guide is designed to help users train a YOLOv7 object detection model using Docker. It covers setting up the Docker environment, preparing the dataset, configuring necessary files, and running the training process. By the end of this guide, you will be equipped to perform advanced object detection tasks with your trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33db6763-45f7-41b5-b681-b9588c1a2c05",
      "metadata": {
        "id": "33db6763-45f7-41b5-b681-b9588c1a2c05"
      },
      "source": [
        "## 1. Setting Up Docker Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a7b37b-62d7-497f-a66e-5239ade46cd3",
      "metadata": {
        "id": "53a7b37b-62d7-497f-a66e-5239ade46cd3"
      },
      "source": [
        "## Open the Terminal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f30bdf7-add7-40df-b58d-5d21743836a6",
      "metadata": {
        "id": "5f30bdf7-add7-40df-b58d-5d21743836a6"
      },
      "source": [
        "[texto del enlace](https://)Begin by accessing the terminal on your server. This is where you will enter commands to control Docker and set up your training environment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "503eb30a-a0a1-4208-9d60-71f1fd66891f",
      "metadata": {
        "id": "503eb30a-a0a1-4208-9d60-71f1fd66891f"
      },
      "source": [
        "## Docker Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf7d7d0f-c675-4cf5-915d-aa214808778e",
      "metadata": {
        "id": "bf7d7d0f-c675-4cf5-915d-aa214808778e"
      },
      "source": [
        "If you are not familiar with Docker, it's a platform that allows you to containerize software configurations and dependencies, making it easier to run applications reliably across different computing environments. For YOLOv7 training, Docker ensures that all dependencies are neatly packaged without affecting other configurations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7598aec6-5c1b-4572-a476-229bdc471dac",
      "metadata": {
        "id": "7598aec6-5c1b-4572-a476-229bdc471dac"
      },
      "source": [
        "## Prepare the Dataset and Docker"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceafe995-49c0-4d36-b741-722d942090ca",
      "metadata": {
        "id": "ceafe995-49c0-4d36-b741-722d942090ca"
      },
      "source": [
        "## For Datasets on Your User Account:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d766a2-5ba3-42f9-8c24-fc4624587933",
      "metadata": {
        "id": "70d766a2-5ba3-42f9-8c24-fc4624587933"
      },
      "source": [
        "If your dataset is already on your server and you want to use it directly from its current location, use the following command to start a Docker container and mount the dataset folder as a volume in the container:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docker run -it --name <prueba10> -v /home/<fcalderon>/Fogsphere_datasets:/root/src/darknet/<NewFolder> yolo_darknet:cuda12 bash -c \"mkdir -p /root/src/darknet/<NewFolder> && ls -la /root/src/darknet/<NewFolder> && bash\""
      ],
      "metadata": {
        "id": "RWZ_EITGTmD9"
      },
      "id": "RWZ_EITGTmD9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6c9bf36f-750e-4e96-91ca-ec0c4642b594",
      "metadata": {
        "id": "6c9bf36f-750e-4e96-91ca-ec0c4642b594"
      },
      "source": [
        "This command does several things:\n",
        "\n",
        "* docker run starts a new Docker container.\n",
        "\n",
        "* -it allows you to interact with the container.\n",
        "\n",
        "* --name prueba10 names your container for easier reference.\n",
        "\n",
        "* -v mounts a volume, linking a directory on your server to a directory in the container.\n",
        "\n",
        "* yolo_darknet:cuda12 specifies the Docker image configured with CUDA 12, optimized for GPU use in deep learning.\n",
        "\n",
        "* The final bash -c part executes a series of commands when the container starts, primarily to set up the directory structure and verify that everything is in place."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec47806-a87a-49e6-8df6-a910e0ee0810",
      "metadata": {
        "id": "bec47806-a87a-49e6-8df6-a910e0ee0810"
      },
      "source": [
        "## For Datasets in Repositories or External Sources:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2833d1f1-8d41-4984-b31a-9e54499479eb",
      "metadata": {
        "id": "2833d1f1-8d41-4984-b31a-9e54499479eb"
      },
      "source": [
        "\n",
        "If you need to download the dataset or it is not on your local user account, you can start a simpler Docker container and handle the data transfer manually or through scripts:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docker run -it --name <pipeline> yolo_darknet:cuda12 bash\n"
      ],
      "metadata": {
        "id": "168zbeAjTqZO"
      },
      "id": "168zbeAjTqZO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "46989636-92e7-422d-9d0a-ea775c917e40",
      "metadata": {
        "id": "46989636-92e7-422d-9d0a-ea775c917e40"
      },
      "source": [
        "After the container starts, you can use git clone, wget, or similar commands to populate your dataset inside the container."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "279419c2-bf7f-4d07-9da4-0f6728706279",
      "metadata": {
        "id": "279419c2-bf7f-4d07-9da4-0f6728706279"
      },
      "source": [
        "## 2. Generating Dataset Path Files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a06fde9-7dfb-43af-8c59-e1a47ea79e8c",
      "metadata": {
        "id": "0a06fde9-7dfb-43af-8c59-e1a47ea79e8c"
      },
      "source": [
        "The training and validation processes require text files listing the paths to the respective images. These files are crucial for YOLOv7 to locate and use the images during training. Use a Python script to generate these files automatically:"
      ]
    },
    {
      "cell_type": "raw",
      "id": "f8870d1e-35fc-436c-bd52-392d46324691",
      "metadata": {
        "id": "f8870d1e-35fc-436c-bd52-392d46324691"
      },
      "source": [
        "import os\n",
        "\n",
        "def generate_paths_file(folder_path, output_file_name):\n",
        "    # This function searches for all .jpg or .JPG files in the specified directory and writes their paths to a text file.\n",
        "    jpg_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.JPG'))]\n",
        "    with open(output_file_name, 'w') as file:\n",
        "        for jpg_file in jpg_files:\n",
        "            file.write(f\"{folder_path}/{jpg_file}\\n\")\n",
        "\n",
        "    print(f\"List of .jpg files saved in {output_file_name}\")\n",
        "\n",
        "# Example usage:\n",
        "generate_paths_file('/root/src/darknet/NewFolder/Dataset_PPE-ExplicitForklift_19-cls/images/val', 'validation.txt')\n",
        "generate_paths_file('/root/src/darknet/NewFolder/Dataset_PPE-ExplicitForklift_19-cls/images/train', 'training.txt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "481ccb39-5fe6-4c10-8a65-eb955b521ecc",
      "metadata": {
        "id": "481ccb39-5fe6-4c10-8a65-eb955b521ecc"
      },
      "source": [
        "This script should be run inside the Docker container where the dataset resides."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df5426eb-7238-442d-9af4-dcf92183fd27",
      "metadata": {
        "id": "df5426eb-7238-442d-9af4-dcf92183fd27"
      },
      "source": [
        "## 3. Configuring the .data and .names Files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b31d169-d85a-49c0-8998-f231ee55249a",
      "metadata": {
        "id": "9b31d169-d85a-49c0-8998-f231ee55249a"
      },
      "source": [
        "## .data File Configuration:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16959751-efb1-46ec-a55c-f02205025206",
      "metadata": {
        "id": "16959751-efb1-46ec-a55c-f02205025206"
      },
      "source": [
        "This file links YOLOv7 to its necessary resources:"
      ]
    },
    {
      "cell_type": "raw",
      "id": "2aa97d18-b143-4e15-9bc5-5a0b9f6db236",
      "metadata": {
        "id": "2aa97d18-b143-4e15-9bc5-5a0b9f6db236"
      },
      "source": [
        "classes = 19\n",
        "train = /root/src/darknet/NewFolder/training.txt\n",
        "valid = /root/src/darknet/NewFolder/validation.txt\n",
        "names = /root/src/darknet/NewFolder/dataset.names\n",
        "backup = /root/src/darknet/NewFolder/backup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ff66a98-89e4-4a8d-85f6-dd86ab93f04e",
      "metadata": {
        "id": "4ff66a98-89e4-4a8d-85f6-dd86ab93f04e"
      },
      "source": [
        "* classes specifies the number of different objects the model should recognize.\n",
        "* train and valid point to the text files you generated, which list the image files for training and validation.\n",
        "* names points to a file listing the names of the classes.\n",
        "* backup is where trained model weights will be saved periodically."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fee9fd1-ed9a-46ce-9083-b477225e2465",
      "metadata": {
        "id": "1fee9fd1-ed9a-46ce-9083-b477225e2465"
      },
      "source": [
        "## .names File Configuration:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad8245bc-a726-4a39-8ad2-a5f219cb938c",
      "metadata": {
        "id": "ad8245bc-a726-4a39-8ad2-a5f219cb938c"
      },
      "source": [
        "Create a .names file listing each class name on a new line, in the same order as the class labels used during dataset preparation. This file helps YOLOv7 to map its outputs to human-readable class names."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a680be9-5e19-41e1-8151-20c50171e195",
      "metadata": {
        "id": "1a680be9-5e19-41e1-8151-20c50171e195"
      },
      "source": [
        "## 4. Editing the Configuration File (.cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3978150d-b5cc-4ef5-860d-780ea4c3c2bf",
      "metadata": {
        "id": "3978150d-b5cc-4ef5-860d-780ea4c3c2bf"
      },
      "source": [
        "Select the appropriate YOLOv7 configuration file (e.g., yolov7-tiny.cfg for a faster, less resource-intensive model). You'll need to edit several fields:\n",
        "\n",
        "* batch and subdivisions control how many images are processed at a time; tweak these based on your GPU's memory.\n",
        "* width and height should be multiples of 32 and may be increased to improve accuracy at the cost of speed.\n",
        "* max_batches should be at least 2000 times the number of classes, and steps should be 80% and 90% of max_batches.\n",
        "* Update filters in the [convolutional] layers just before each [yolo] layer. This should be (classes + 5) * 3."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Downloading Pre-trained Weights for YOLOv7"
      ],
      "metadata": {
        "id": "NKCvD16JSgZQ"
      },
      "id": "NKCvD16JSgZQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For those looking to enhance the training process of the YOLOv7 model, utilizing pre-trained weights is highly advantageous. These weights offer a strong foundation, potentially improving training speed and model effectiveness.\n",
        "\n",
        "**Instructions for Downloading Pre-trained Weights**:\n",
        "\n",
        "1. Access the GitHub releases page of the Darknet repository specifically tailored for YOLOv7.\n",
        "2. In the [releases section](https://github.com/AlexeyAB/darknet/releases), locate the **`.conv`** files which are used for YOLOv7. These files contain weights pre-trained on a specific dataset and are intended to be used as a starting point for further training.\n",
        "3. Choose the appropriate **`.conv`** file according to the YOLOv7 configuration you intend to train, such as **`yolov7.conv`**.\n",
        "4. Download the selected weights file from the page.\n",
        "\n",
        "Utilizing these pre-trained weights allows the model to skip the initial generic learning phase, directly starting with a more advanced understanding of the task at hand. This can significantly reduce training time and computational resource consumption."
      ],
      "metadata": {
        "id": "pvXf61p6SlNQ"
      },
      "id": "pvXf61p6SlNQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81454406-4598-443e-9279-91ff99a09f7a",
      "metadata": {
        "id": "81454406-4598-443e-9279-91ff99a09f7a"
      },
      "outputs": [],
      "source": [
        "\n",
        "wget https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov7.conv.132 -O yolov7.conv.132"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. YOLOv7 Model Training Command Template\n",
        "\n",
        "For training the YOLOv7 model using the Darknet framework, you can use the following command template. This template is particularly useful when you're ready to begin training with a configuration and dataset that are pre-set and prepared."
      ],
      "metadata": {
        "id": "hfSUgU4ISxWl"
      },
      "id": "hfSUgU4ISxWl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Command to train YOLOv7 model using Darknet\n",
        "darknet detector train [path_to_data_file] [path_to_config_file] [path_to_weights_file] -show -map\n"
      ],
      "metadata": {
        "id": "6IpNrfXYS54v"
      },
      "id": "6IpNrfXYS54v",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}